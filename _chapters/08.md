---
title: Performance of Different Models on Different NLP Tasks
---

We summarize the performance of a series of deep learning methods on standard datasets developed in recent years on 7 major NLP topics in Tables [REF]-[REF]. Our goal is to show the readers common datasets used in the community and state-of-the-art results with different models.

<table>
  <tr>
    <th>Paper</th>
    <th>Model</th>
    <th>WSJ-PTB (per-token accuracy %)</th>
  </tr>
  <tr>
    <td>CITE</td>
    <td>SVM with manual feature pattern</td>
    <td>97.16</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>MLP with word embeddings + CRF</td>
    <td>97.29</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>MLP with character+word embeddings</td>
    <td>97.32</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>LSTM</td>
    <td>97.29</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>Bidirectional LSTM</td>
    <td>97.40</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>LSTM-CRF</td>
    <td>97.54</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>Bidirectional LSTM-CRF</td>
    <td>97.55</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>Transition-based neural network</td>
    <td>97.45</td>
  </tr>
  <tr>
    <td>CITE</td>
    <td>DMN</td>
    <td>97.56</td>
  </tr>
</table>

*Table 2: POS tagging*

